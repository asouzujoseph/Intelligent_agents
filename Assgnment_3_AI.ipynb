{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a935bd4a",
   "metadata": {},
   "source": [
    "Name: Nnamdi Joseph Asouzu <br>\n",
    "Student number: X487118   <br>\n",
    "Course: Intelligent Agents <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b78d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from collections import namedtuple\n",
    "import random\n",
    "import copy\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "import h5py\n",
    "import networkx as nx\n",
    "from pomegranate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c28429",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the orientation of the agent at each box in the grid i.e the direction where the agent is facing\n",
    "class Orientation(Enum):\n",
    "    south = 1\n",
    "    east = 2\n",
    "    west = 3\n",
    "    north = 4\n",
    "        \n",
    "    @property\n",
    "    def move_right(self):\n",
    "        move_right = {\n",
    "            Orientation.west: Orientation.north,  ### if the agent is facing west then to move right it has to face north\n",
    "            Orientation.east: Orientation.south,  ### if the agent is facing east then to move right it has to face south\n",
    "            Orientation.north: Orientation.east,  ### if the agent is facing north then to move right it has to face east\n",
    "            Orientation.south: Orientation.west   ### if the agent is facing south then to move right it has to face west\n",
    "        }\n",
    "        new_orientation = move_right.get(self)\n",
    "        return new_orientation\n",
    "    \n",
    "    @property\n",
    "    def move_left(self):\n",
    "        move_left = {\n",
    "            Orientation.east: Orientation.north, ### if the agent is facing east then to move left it has to face north\n",
    "            Orientation.south: Orientation.east, ### if the agent is facing south then to move left it has to face east\n",
    "            Orientation.north: Orientation.west, ### if the agent is facing north then to move left it has to face west\n",
    "            Orientation.west: Orientation.south  ### if the agent is facing west then to move left it has to face south\n",
    "        }\n",
    "        new_orientation = move_left.get(self)\n",
    "        return new_orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd8d2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### define the coordinates of the grid / environment\n",
    "### the library automatically names the first value in the tuple x and the second value to be y  \n",
    "class Coords(namedtuple('Coords', 'x y')):\n",
    "    def adjacent_cells(self, box_width, box_height):\n",
    "        neighbors = []\n",
    "        if self.x > 0: # to left\n",
    "            neighbors.append(Coords(self.x - 1, self.y))\n",
    "        if self.x < (box_width - 1): # to right\n",
    "            neighbors.append(Coords(self.x + 1, self.y))\n",
    "        if self.y > 0: # below\n",
    "            neighbors.append(Coords(self.x, self.y - 1))\n",
    "        if self.y < (box_height - 1): # above\n",
    "            neighbors.append(Coords(self.x, self.y + 1))\n",
    "        return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ffc21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define actions of the agent\n",
    "class Action():\n",
    "    ## every action of the object will have the following attributes which are all set to False at the start of the game\n",
    "    def __init__(self, forward=False, turn_left=False, turn_right=False,shoot=False, grab=False, climb=False):\n",
    "        self.forward = forward\n",
    "        self.turn_left = turn_left\n",
    "        self.turn_right = turn_right\n",
    "        self.shoot = shoot\n",
    "        self.grab = grab\n",
    "        self.climb = climb\n",
    "        \n",
    "     ## define methods to turn on the actions\n",
    "    @classmethod\n",
    "    def forward(cls):\n",
    "        return Action(forward=True)\n",
    "\n",
    "    @classmethod\n",
    "    def turn_left(cls):\n",
    "        return Action(turn_left=True)\n",
    "\n",
    "    @classmethod\n",
    "    def turn_right(cls):\n",
    "        return Action(turn_right=True)\n",
    "\n",
    "    @classmethod\n",
    "    def shoot(cls):\n",
    "        return Action(shoot=True)\n",
    "\n",
    "    @classmethod\n",
    "    def grab(cls):\n",
    "        return Action(grab=True)\n",
    "\n",
    "    @classmethod\n",
    "    def climb(cls):\n",
    "        return Action(climb=True)\n",
    " \n",
    "    ### display the action taken by the agent in each iteration\n",
    "    def display(self):\n",
    "        if self.forward:\n",
    "            action= \"Action: forward\"\n",
    "        elif self.turn_left:\n",
    "            action = \"Action: turn_left\"\n",
    "        elif self.turn_right:\n",
    "            action = \"Action: turn_right\"\n",
    "        elif self.shoot:\n",
    "            action = \"Action: shoot\"\n",
    "        elif self.grab:\n",
    "            action = \"Action: grab\"\n",
    "        else:\n",
    "            action = \"Action: climb\"\n",
    "        print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae45a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define the percepts sensed by the agent \n",
    "class Percept():\n",
    "    def __init__(self, stench, breeze, glitter, bump, scream, game_over, reward):\n",
    "        self.stench = stench   ### stench of the Wumpus\n",
    "        self.breeze = breeze  ## breeze from the pit\n",
    "        self.glitter = glitter  ### glitter of gold\n",
    "        self.bump = bump     ## bump into a wall\n",
    "        self.scream = scream   ## scream of the wumpus\n",
    "        self.game_over = game_over  ## agent is dead\n",
    "        self.reward = reward   ### agent is rewarded\n",
    "    ## display the percepts\n",
    "    def display(self):\n",
    "        print(\"stench: {}, breeze: {}, glitter: {}, bump: {}, scream: {}, game_over: {}, reward: {}\"\n",
    "              .format(self.stench, self.breeze, self.glitter, self.bump, self.scream, self.game_over, self.reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a78e98e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState():\n",
    "    ## methods to modify the agent state\n",
    "    def __init__(self, location=Coords(0, 0), orientation=Orientation.east, has_gold=False, has_arrow=True, is_alive=True):\n",
    "        self.location = location\n",
    "        self.orientation = orientation\n",
    "        self.has_gold = has_gold\n",
    "        self.has_arrow = has_arrow\n",
    "        self.is_alive = is_alive\n",
    "    \n",
    "    def turn_left(self):\n",
    "        new_state = copy.deepcopy(self)  ## create a fresh instance / copy of the agent for each iteration\n",
    "        new_state.orientation = new_state.orientation.move_left  # change the orientation to face left relative to the initial orientation\n",
    "        return new_state\n",
    "\n",
    "    \n",
    "    def turn_right(self):\n",
    "        new_state = copy.deepcopy(self) ## create a fresh instance / copy of the agent for ech iteration\n",
    "        new_state.orientation = new_state.orientation.move_right  # change the orientation to face right relative to the initial orientation\n",
    "        return new_state\n",
    "    \n",
    "    def forward(self, box_width, box_height):\n",
    "        if self.orientation == Orientation.north: \n",
    "            '''\n",
    "            # if the agent is facing north, to move forward, x coord will be the same while y coord will increase by 1 \n",
    "            except if the agent is already at the edge of the grid whereby the box height will decrease by 1 and \n",
    "            the agent will be unable to move forward as it has bumped into a wall\n",
    "            '''\n",
    "            new_loc = Coords(self.location.x, min(3, self.location.y + 1)) \n",
    "        elif self.orientation == Orientation.south:\n",
    "            '''\n",
    "            # if the agent is facing south, to move forward, x coord will be the same while y coord will decrease by 1 \n",
    "            except if the agent is already at the edge of the grid whereby \n",
    "            the agent will be unable to move forward as it has bumped into a wall\n",
    "            '''\n",
    "            new_loc = Coords(self.location.x, max(0, self.location.y - 1))\n",
    "        elif self.orientation == Orientation.east:\n",
    "            '''\n",
    "            # if the agent is facing east, to move forward, x coord will be increase by 1 while y coord will remain the same\n",
    "            except if the agent is already at the edge of the grid whereby \n",
    "            the agent will be unable to move forward as it has bumped into a wall\n",
    "            '''\n",
    "            new_loc = Coords(min(box_width - 1, self.location.x + 1), self.location.y)\n",
    "        else:\n",
    "            '''\n",
    "            # if the agent is facing east, to move forward, x coord will be decrease by 1 while y coord will remain the same\n",
    "            except if the agent is already at the edge of the grid whereby \n",
    "            the agent will be unable to move forward as it has bumped into a wall\n",
    "            '''\n",
    "            new_loc = Coords(max(0, self.location.x - 1), self.location.y) # if Orientation.west\n",
    "        new_state = copy.deepcopy(self)\n",
    "        new_state.location = new_loc\n",
    "        return new_state\n",
    "    \n",
    "    def apply_action(self, action, box_width, box_height):\n",
    "        if action.forward:\n",
    "            return self.forward(box_width, box_height)\n",
    "        if action.turn_left:\n",
    "            return self.turn_left()\n",
    "        if action.turn_right:\n",
    "            return self.turn_right()\n",
    "        if action.shoot:\n",
    "            return self.use_arrow()\n",
    "        if action.climb:\n",
    "            return self\n",
    "    \n",
    "    def use_arrow(self):\n",
    "        new_state = copy.deepcopy(self)\n",
    "        new_state.has_arrow = False\n",
    "        return new_state\n",
    "    \n",
    "    def show(self):\n",
    "        print(\"location: {}, orientation: {}, has_gold: {}, has_arrow: {}, is_alive: {}\"\n",
    "              .format(self.location, self.orientation, self.has_gold, self.has_arrow, self.is_alive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ecae784",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper functions     \n",
    "# Create a list with all locations\n",
    "def list_all_locations(box_width, box_height):\n",
    "    all_cells = []\n",
    "    for x in range(box_width):\n",
    "        for y in range(box_height):\n",
    "            all_cells.append(Coords(x, y))\n",
    "    return all_cells\n",
    "        \n",
    "# Create locations for gold and wumpus\n",
    "def random_location_except_origin(box_width, box_height):\n",
    "    coordinates = []     ## empty list for storing coordinates\n",
    "    for col in range(box_width): ## for each value in the range of the box width i.e 0,1,2,3\n",
    "        for row in range(box_height): ## for each value in the range of the box height i.e 0,1,2,3\n",
    "            cell = Coords(x=col, y=row) # make a tuple of the different combinations\n",
    "            coordinates.append(cell) ## append this tuple to the list\n",
    "    coordinates.remove(Coords(0, 0)) # take out the first coordinate which is the starting point of the agent\n",
    "    return random.choice(coordinates) ## randomly select a value in the list of coordinates for the location of the gold  and wumpus\n",
    "\n",
    "\n",
    "# Create pit locations\n",
    "def create_pit_locations(box_width, box_height, pit_prob):\n",
    "    coordinates = []    ## empty list for storing coordinates\n",
    "    pit_locations = []   ## empty list for storing pit locations\n",
    "    for col in range(box_width): ## for each value in the range of the box width i.e 0,1,2,3\n",
    "        for row in range(box_height):   ## for each value in the range of the box height i.e 0,1,2,3\n",
    "            cell = Coords(x=col, y=row)  # make a tuple of the different combinations\n",
    "            coordinates.append(cell) ## append this tuple to the list\n",
    "    coordinates.remove(Coords(0, 0))   # take out the first coordinate which is the starting point of the agent\n",
    "    for loc in coordinates: ## for each value in the list \n",
    "        if random.random() < pit_prob:  ### whenever the random.random value is less than 0.2\n",
    "            pit_locations.append(loc)  ### select that coordinate tuple as the pit location\n",
    "    return pit_locations\n",
    "\n",
    "def encode_action_to_int(action):\n",
    "    if action.forward:\n",
    "        action_int = 0\n",
    "    elif action.turn_left:\n",
    "        action_int = 1\n",
    "    elif action.turn_right:\n",
    "        action_int = 2\n",
    "    elif action.shoot:\n",
    "        action_int = 3\n",
    "    elif action.grab:\n",
    "        action_int = 4\n",
    "    else: # climb\n",
    "        action_int = 5\n",
    "    return action_int\n",
    "\n",
    "def decode_action_index(index):\n",
    "    actions = [Action.forward(), Action.turn_left(), Action.turn_right(), Action.shoot(), Action.grab(), Action.climb()]\n",
    "    return actions[index]\n",
    "\n",
    "# Function to load the experience buffer from HDF5 file\n",
    "\n",
    "def load_experience(h5file):\n",
    "    return ExperienceBuffer(\n",
    "        states=np.array(h5file['experience']['states']),\n",
    "        actions=np.array(h5file['experience']['actions']),\n",
    "        rewards=np.array(h5file['experience']['rewards']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c4233c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the environment    \n",
    "class Environment():\n",
    "    def __init__(self, box_width, box_height, pit_prob, allow_climb_without_gold, agent, pit_locations,terminated, wumpus_loc, wumpus_alive, gold_loc): \n",
    "        self.box_width = box_width\n",
    "        self.box_height = box_height\n",
    "        self.pit_prob = pit_prob\n",
    "        self.allow_climb_without_gold = allow_climb_without_gold\n",
    "        self.agent = agent\n",
    "        self.pit_locations = pit_locations\n",
    "        self.terminated = terminated\n",
    "        self.wumpus_loc = wumpus_loc\n",
    "        self.wumpus_alive = wumpus_alive\n",
    "        self.gold_loc = gold_loc\n",
    "        \n",
    "    \n",
    "    def is_pit_at(self, coords):\n",
    "        return coords in self.pit_locations\n",
    "    \n",
    "    def is_wumpus_at(self, coords):\n",
    "        return coords == self.wumpus_loc\n",
    "    \n",
    "    def is_agent_at(self, coords):\n",
    "        return coords == self.agent.location\n",
    "    \n",
    "    def is_glitter(self):\n",
    "        return self.gold_loc == self.agent.location\n",
    "    \n",
    "    def is_gold_at(self, coords):\n",
    "        return coords == self.gold_loc\n",
    "    \n",
    "    def wumpus_in_line_of_fire(self):\n",
    "        if self.agent.orientation == Orientation.west:\n",
    "            '''\n",
    "            the agent and wumpus will be on the same y axis. The x coord of the agent will be higher than the x coord of the wumpus\n",
    "            '''\n",
    "            return self.agent.location.x > self.wumpus_loc.x and self.agent.location.y == self.wumpus_loc.y\n",
    "        if self.agent.orientation == Orientation.east:\n",
    "            '''\n",
    "            the agent and wumpus will be on the same y axis. The x coord of the agent will be lower than the x coord of the wumpus\n",
    "            '''\n",
    "            return self.agent.location.x < self.wumpus_loc.x and self.agent.location.y == self.wumpus_loc.y\n",
    "        if self.agent.orientation == Orientation.south:\n",
    "            '''\n",
    "            the agent and wumpus will be on the same x axis. The y coord of the agent will be higher than the y coord of the wumpus\n",
    "            '''\n",
    "            return self.agent.location.x == self.wumpus_loc.x and self.agent.location.y > self.wumpus_loc.y\n",
    "        if self.agent.orientation == Orientation.north:\n",
    "            '''\n",
    "            the agent and wumpus will be on the same x axis. The y coord of the agent will be lower than the y coord of the wumpus\n",
    "            '''\n",
    "            return self.agent.location.x == self.wumpus_loc.x and self.agent.location.y < self.wumpus_loc.y\n",
    "    \n",
    "    def kill_attempt_successful(self):\n",
    "        '''\n",
    "        For the kill attempt to succeed, the agent must have an arrow, wumpus must be alive and in the line of fire\n",
    "        '''\n",
    "        return self.agent.has_arrow and self.wumpus_alive and self.wumpus_in_line_of_fire()\n",
    "    \n",
    "    def adjacent_cells(self, coords=Coords(0, 0)):\n",
    "        return [\n",
    "            Coords(coords.x - 1, coords.y) if coords.x > 0 else None, # to the left\n",
    "            Coords(coords.x + 1, coords.y) if coords.x < (self.box_width - 1) else None,  # to the right\n",
    "            Coords(coords.x, coords.y - 1) if coords.y > 0 else None, # below\n",
    "            Coords(coords.x, coords.y + 1) if coords.y < (self.box_height - 1) else None, # above\n",
    "        ]\n",
    "    \n",
    "    def is_pit_adjacent(self, coords):\n",
    "        for cell in self.adjacent_cells(coords):\n",
    "            if cell is None:\n",
    "                continue\n",
    "            if cell in self.pit_locations:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_wumpus_adjacent(self, coords):\n",
    "        for cell in self.adjacent_cells(coords):\n",
    "            if cell is None:\n",
    "                continue\n",
    "            if self.is_wumpus_at(cell):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_breeze(self):\n",
    "        return self.is_pit_adjacent(self.agent.location)\n",
    "    \n",
    "    def is_stench(self):\n",
    "        return self.is_wumpus_adjacent(self.agent.location) or self.is_wumpus_at(self.agent.location)\n",
    "    \n",
    "    def apply_action(self, action):\n",
    "        if self.terminated:\n",
    "            return (self, Percept(False, False, False, False, False, True, 0))\n",
    "        else:\n",
    "            if action.forward:\n",
    "                moved_agent = self.agent.forward(self.box_width, self.box_height) # call the forward attribute of action class\n",
    "                death = (self.is_wumpus_at(moved_agent.location) and self.wumpus_alive) or self.is_pit_at(moved_agent.location) ## if wumpus and agent have the same location and wumpus is still alive or the agent fell into the pit\n",
    "                new_agent = copy.deepcopy(moved_agent)\n",
    "                new_agent.is_alive = not death\n",
    "                new_gold_loc = new_agent.location if self.agent.has_gold else self.gold_loc\n",
    "                new_env = Environment(self.box_width, self.box_height, self.pit_prob, self.allow_climb_without_gold, \n",
    "                                      new_agent, self.pit_locations, death, self.wumpus_loc, self.wumpus_alive, new_gold_loc)\n",
    "                percept = Percept(new_env.is_stench(), new_env.is_breeze(), new_env.is_glitter(), \n",
    "                                  new_agent.location == self.agent.location, False, death, \n",
    "                                  -1 if new_agent.is_alive else -1001)\n",
    "                return (new_env, percept)\n",
    "            \n",
    "            if action.turn_left:\n",
    "                new_env = Environment(self.box_width, self.box_height, self.pit_prob, self.allow_climb_without_gold, \n",
    "                                      self.agent.turn_left(), self.pit_locations, self.terminated, self.wumpus_loc, \n",
    "                                      self.wumpus_alive, self.gold_loc)\n",
    "                percept = Percept(self.is_stench(), self.is_breeze(), self.is_glitter(), False, False, False, -1)\n",
    "                return (new_env, percept)\n",
    "            \n",
    "            if action.turn_right:\n",
    "                new_env = Environment(self.box_width, self.box_height, self.pit_prob, self.allow_climb_without_gold, \n",
    "                                      self.agent.turn_right(), self.pit_locations, self.terminated, self.wumpus_loc, \n",
    "                                      self.wumpus_alive, self.gold_loc)\n",
    "                percept = Percept(self.is_stench(), self.is_breeze(), self.is_glitter(), False, False, False, -1)\n",
    "                return (new_env, percept)\n",
    "            \n",
    "            if action.grab:\n",
    "                new_agent = copy.deepcopy(self.agent)\n",
    "                new_agent.has_gold = self.is_glitter()\n",
    "                new_gold_loc = new_agent.location if new_agent.has_gold else self.gold_loc\n",
    "                new_env = Environment(self.box_width, self.box_height, self.pit_prob, self.allow_climb_without_gold, \n",
    "                                      new_agent, self.pit_locations, self.terminated, self.wumpus_loc, self.wumpus_alive, \n",
    "                                      new_gold_loc)\n",
    "                percept = Percept(self.is_stench(), self.is_breeze(), self.is_glitter(), False, False, False, -1)\n",
    "                return (new_env, percept)\n",
    "            \n",
    "            if action.climb:\n",
    "                starting_point = self.agent.location == Coords(0, 0)\n",
    "                #### agent can climb out of the cave with gold or without gold if it is at location Coords(0,0)\n",
    "                success = self.agent.has_gold or starting_point\n",
    "                game_over = success \n",
    "                new_env = Environment(self.box_width, self.box_height, self.pit_prob, self.allow_climb_without_gold, \n",
    "                                      self.agent, self.pit_locations, game_over, self.wumpus_loc, self.wumpus_alive,  self.gold_loc)\n",
    "                percept = Percept(self.is_stench(), self.is_breeze(), self.is_glitter(), False, False,game_over,  \n",
    "                                  999 if success else -1)\n",
    "                return (new_env, percept)\n",
    "            \n",
    "            if action.shoot:\n",
    "                had_arrow = self.agent.has_arrow\n",
    "                wumpus_killed = self.kill_attempt_successful()\n",
    "                new_agent = copy.deepcopy(self.agent)\n",
    "                new_agent.has_arrow = False\n",
    "                new_env = Environment(self.box_width, self.box_height, self.pit_prob, self.allow_climb_without_gold, \n",
    "                                      new_agent, self.pit_locations, self.terminated, self.wumpus_loc, \n",
    "                                      self.wumpus_alive and (not wumpus_killed), self.gold_loc)\n",
    "                percept = Percept(self.is_stench(), self.is_breeze(), self.is_glitter(), False, wumpus_killed, False, \n",
    "                                  -11 if had_arrow else -1)\n",
    "                return (new_env, percept)\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def new_game(cls, box_width, box_height, pit_prob, allow_climb_without_gold):\n",
    "        new_pit_locations = create_pit_locations(box_width, box_height, pit_prob)\n",
    "        new_wumpus_loc = random_location_except_origin(box_width, box_height)\n",
    "        new_gold_loc = random_location_except_origin(box_width, box_height)\n",
    "        env = Environment(box_width, box_height, pit_prob,allow_climb_without_gold, \n",
    "                          AgentState(), new_pit_locations, False, new_wumpus_loc, True, new_gold_loc)\n",
    "        percept = Percept(env.is_stench(), env.is_breeze(), False, False, False, False, 0.0)\n",
    "        return (env, percept)\n",
    "    \n",
    "    \n",
    "    def visualizer(self):\n",
    "        wumpus_symbol = \"W\" if self.wumpus_alive else \"w\"\n",
    "        all_rows = []\n",
    "        for y in range(self.box_height - 1, -1, -1):\n",
    "            row = []\n",
    "            for x in range (self.box_width):\n",
    "                agent =  '>' if self.agent.orientation ==Orientation.east and self.is_agent_at(Coords(x, y)) else  '<' if self.agent.orientation ==Orientation.west and self.is_agent_at(Coords(x, y)) else '^' if self.agent.orientation ==Orientation.north and self.is_agent_at(Coords(x, y)) else 'v' if self.agent.orientation ==Orientation.south and self.is_agent_at(Coords(x, y)) else \" \"\n",
    "                pit = \"P\" if self.is_pit_at(Coords(x, y)) else \" \"\n",
    "                gold = \"G\" if self.is_gold_at(Coords(x, y)) else \" \"\n",
    "                wumpus = wumpus_symbol if self.is_wumpus_at(Coords(x, y)) else \" \"\n",
    "                cell = agent + pit + gold + wumpus\n",
    "                row.append(cell)\n",
    "            row_str = \"|\".join(row)\n",
    "            all_rows.append(row_str)\n",
    "        final_str = \"\\n\".join(all_rows)\n",
    "        print(final_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9065f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ExperienceBuffer class to store the states, actions and rewards as NumPy arrays\n",
    "\n",
    "class ExperienceBuffer:\n",
    "    def __init__(self, states, actions, rewards):\n",
    "        self.states = states\n",
    "        self.actions = actions\n",
    "        self.rewards = rewards\n",
    "    \n",
    "    def serialize(self, h5file):\n",
    "        h5file.create_group('experience')\n",
    "        h5file['experience'].create_dataset('states', data=self.states)\n",
    "        h5file['experience'].create_dataset('actions', data=self.actions)\n",
    "        h5file['experience'].create_dataset('rewards', data=self.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "686b20d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ExperienceCollector class to collect all the states, decisions and rewards (as Python lists)\n",
    "\n",
    "class ExperienceCollector:\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "    \n",
    "    def store_state(self, state):\n",
    "        self.states.append(state)\n",
    "    \n",
    "    def store_action(self, action):\n",
    "        self.actions.append(action)\n",
    "    \n",
    "    def store_reward(self, reward):\n",
    "        self.rewards.append(reward)\n",
    "    \n",
    "    def to_buffer(self):\n",
    "        return ExperienceBuffer(\n",
    "            states=np.array(self.states), \n",
    "            actions=np.array(self.actions), \n",
    "            rewards=np.array(self.rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5987690",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def select_action(self, percept):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ca0fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbAgent(Agent):\n",
    "    \n",
    "    def __init__(self, box_width, box_height, pit_prob, agent_state, beeline_action_list, \n",
    "                 breeze_locations, stench_locations, visited_locations, heard_scream, \n",
    "                 inferred_pit_probs, inferred_wumpus_probs, perceives_glitter, perceives_bump):\n",
    "        self.box_width = box_width\n",
    "        self.box_height = box_height\n",
    "        self.pit_prob = pit_prob\n",
    "        self.agent_state = agent_state\n",
    "        self.beeline_action_list = beeline_action_list\n",
    "        self.breeze_locations = set(breeze_locations)\n",
    "        self.stench_locations = set(stench_locations)\n",
    "        self.visited_locations = set(visited_locations)\n",
    "        self.heard_scream = heard_scream\n",
    "        self.inferred_pit_probs = inferred_pit_probs\n",
    "        self.inferred_wumpus_probs = inferred_wumpus_probs\n",
    "        self.collector = None\n",
    "        self.perceives_glitter = perceives_glitter\n",
    "        self.perceives_bump = perceives_bump\n",
    "    \n",
    "    def set_collector(self, collector):\n",
    "        self.collector = collector\n",
    "       \n",
    "    def show(self):\n",
    "        self.agent_state.show()\n",
    "        print(\"visited_locations: {}\".format(self.visited_locations))\n",
    "        print(\"breeze_locations: {}\".format(self.breeze_locations))\n",
    "        print(\"stench_locations: {}\".format(self.stench_locations))\n",
    "        print(\"heard_scream: {}\".format(self.heard_scream))\n",
    "        print(\"perceives_glitter: {}\".format(self.perceives_glitter))\n",
    "        print(\"perceives_bump: {}\".format(self.perceives_bump))\n",
    "        print(\"inferred_pit_probs: {}\".format(self.inferred_pit_probs))\n",
    "        print(\"inferred_wumpus_probs: {}\".format(self.inferred_wumpus_probs))\n",
    "        print(\"beeline_action_list: {}\".format([action.show() for action in self.beeline_action_list]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def construct_beeline_plan(self, goal_node, safe_locations):\n",
    "        # Create an undirected two-dimensional grid graph where each node is connected to its four nearest neighbors\n",
    "        G = nx.grid_2d_graph(self.box_width, self.box_height)\n",
    "        not_safe_locations = [node for node in G if node not in safe_locations]\n",
    "        G.remove_nodes_from(not_safe_locations) # keep only safe locations as nodes\n",
    "        \n",
    "        # Compute all shortest simple paths in the graph between source and target (every edge has weight/distance/cost 1)\n",
    "        shortest_paths = [p for p in nx.all_shortest_paths(G, source=self.agent_state.location, target=goal_node)]\n",
    "        \n",
    "        \n",
    "        # Functions for finding the new agent's orientation and required actions to move to the next point on the path\n",
    "        \n",
    "        def north(orientation, a, b):\n",
    "            if a.x > b.x: # move left\n",
    "                return (orientation.move_left, [Action.turn_left(), Action.forward()])\n",
    "            if a.x < b.x: # move right\n",
    "                return (orientation.move_right, [Action.turn_right(), Action.forward()])\n",
    "            if a.y > b.y: # move down\n",
    "                return (orientation.move_left.move_left, [Action.turn_left(), Action.turn_left(), Action.forward()])\n",
    "            if a.y < b.y: # move up\n",
    "                return (orientation, [Action.forward()])\n",
    "        \n",
    "        def south(orientation, a, b):\n",
    "            if a.x > b.x: # move left\n",
    "                return (orientation.move_right, [Action.turn_right(), Action.forward()])\n",
    "            if a.x < b.x: # move right\n",
    "                return (orientation.move_left, [Action.turn_left(), Action.forward()])\n",
    "            if a.y > b.y: # move down\n",
    "                return (orientation, [Action.forward()])\n",
    "            if a.y < b.y: # move up\n",
    "                return (orientation.move_left.move_left, [Action.turn_left(), Action.turn_left(), Action.forward()])\n",
    "            \n",
    "        def east(orientation, a, b):\n",
    "            if a.x > b.x: # move left\n",
    "                return (orientation.move_left.move_left, [Action.turn_left(), Action.turn_left(), Action.forward()])\n",
    "            if a.x < b.x: # move right\n",
    "                return (orientation, [Action.forward()])\n",
    "            if a.y > b.y: # move down\n",
    "                return (orientation.move_right, [Action.turn_right(), Action.forward()])\n",
    "            if a.y < b.y: # move up\n",
    "                return (orientation.move_left, [Action.turn_left(), Action.forward()])\n",
    "        \n",
    "        def west(orientation, a, b):\n",
    "            if a.x > b.x: # move left\n",
    "                return (orientation, [Action.forward()])\n",
    "            if a.x < b.x: # move right\n",
    "                return (orientation.move_left.move_left, [Action.turn_left(), Action.turn_left(), Action.forward()])\n",
    "            if a.y > b.y: # move down\n",
    "                return (orientation.move_left, [Action.turn_left(), Action.forward()])\n",
    "            if a.y < b.y: # move up\n",
    "                return (orientation.move_right, [Action.turn_right(), Action.forward()])\n",
    "        \n",
    "        dict_orientation_to_actions = {\n",
    "            Orientation.north: north, \n",
    "            Orientation.south: south, \n",
    "            Orientation.east: east, \n",
    "            Orientation.west: west\n",
    "        }\n",
    "        \n",
    "        def determine_actions(orientation, a, b):\n",
    "            func = dict_orientation_to_actions.get(orientation)\n",
    "            return func(orientation, a, b)\n",
    "        \n",
    "        # Convert each shortest path into a plan (lists of actions)\n",
    "        plans_list = [] # list with plans for all shortest paths\n",
    "        for path in shortest_paths:\n",
    "            path_coords = [Coords(*node) for node in path] # convert all nodes to the Coords() type\n",
    "            orientation = self.agent_state.orientation\n",
    "            full_plan = []\n",
    "            for i in range(len(path_coords) - 1):\n",
    "                (orientation, actions) = determine_actions(orientation, path_coords[i], path_coords[i + 1])\n",
    "                full_plan.extend(actions)\n",
    "            plans_list.append(full_plan)\n",
    "        \n",
    "        # Find the number of turns for each plan (if more than one shortest path) and choose the plan with fewer turns\n",
    "        if len(plans_list) > 1:\n",
    "            plans_turn_counts = []\n",
    "            for plan in plans_list:\n",
    "                turn_count = 0\n",
    "                for action in plan:\n",
    "                    if action.turn_left or action.turn_right:\n",
    "                        turn_count += 1\n",
    "                plans_turn_counts.append(turn_count)\n",
    "            beeline_plan_index = plans_turn_counts.index(min(plans_turn_counts))\n",
    "            beeline_plan = plans_list[beeline_plan_index]\n",
    "        else:\n",
    "            beeline_plan = plans_list[0]\n",
    "        return beeline_plan\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Choose the first action from the beeline list of actions, update the agent_state and beeline_action_list\n",
    "    def beeline(self, beeline_plan):\n",
    "        beeline_action = beeline_plan[0]\n",
    "        new_agent = copy.deepcopy(self)\n",
    "        new_agent.agent_state = new_agent.agent_state.apply_action(beeline_action, self.box_width, self.box_height)\n",
    "        new_agent.beeline_action_list = beeline_plan[1:]\n",
    "        return (new_agent, beeline_action)\n",
    "       \n",
    "    # Build a probabilistic model for wumpus and stench locations\n",
    "    def create_model_wumpus(self):\n",
    "        \n",
    "        # List of all locations\n",
    "        all_cells = list_all_locations(self.box_width, self.box_height)\n",
    "        \n",
    "        # Discrete distribution for wumpus\n",
    "        wumpus_initial_probs = {}\n",
    "        for cell in all_cells:\n",
    "            if cell.x == 0 and cell.y == 0:\n",
    "                wumpus_initial_probs[cell] = 0.0\n",
    "            else:\n",
    "                wumpus_initial_probs[cell] = 1.0 / (self.box_width * self.box_height - 1)\n",
    "        wumpus_location_dist = DiscreteDistribution(wumpus_initial_probs)\n",
    "        \n",
    "        # Dictionary with wumpus CPDs (a CPD for each cell - probability of wumpus being at this cell and not at other cells)\n",
    "        dict_wumpus_probs = {}\n",
    "        for cell in all_cells:\n",
    "            wumpus_probs = []\n",
    "            for cell_2 in all_cells:\n",
    "                if cell_2 != cell:\n",
    "                    wumpus_probs.append([cell_2, True, 0.0])\n",
    "                    wumpus_probs.append([cell_2, False, 1.0])\n",
    "                else:\n",
    "                    wumpus_probs.append([cell_2, True, 1.0])\n",
    "                    wumpus_probs.append([cell_2, False, 0.0])\n",
    "            dict_wumpus_probs[cell] = ConditionalProbabilityTable(wumpus_probs, [wumpus_location_dist])\n",
    "        \n",
    "        #  Dictionary with stench CPDs (a CPD for each cell - probability of stench at this cell)\n",
    "        dict_stench_probs = {}\n",
    "        dict_neighbors = {} # dict where keys and values are cells and their neighbors respectively\n",
    "        for cell in all_cells:\n",
    "            neighbors = cell.adjacent_cells(self.box_width, self.box_height)\n",
    "            dict_neighbors[cell] = neighbors\n",
    "            if len(neighbors) == 2:\n",
    "                dict_stench_probs[cell] = ConditionalProbabilityTable([[0, 0, 0, 1.0],\n",
    "                                                                       [0, 0, 1, 0.0],\n",
    "                                                                       [0, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 1.0]], [dict_wumpus_probs[neighbors[0]],\n",
    "                                                                                         dict_wumpus_probs[neighbors[1]]])\n",
    "            elif len(neighbors) == 3:\n",
    "                dict_stench_probs[cell] = ConditionalProbabilityTable([[0, 0, 0, 0, 1.0],\n",
    "                                                                       [0, 0, 0, 1, 0.0],\n",
    "                                                                       [0, 0, 1, 0, 0.0],\n",
    "                                                                       [0, 0, 1, 1, 1.0],\n",
    "                                                                       [0, 1, 0, 0, 0.0],\n",
    "                                                                       [0, 1, 0, 1, 1.0],\n",
    "                                                                       [0, 1, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 0, 1, 1.0],\n",
    "                                                                       [1, 0, 1, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 0, 0.0],\n",
    "                                                                       [1, 1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 1, 1.0]], [dict_wumpus_probs[neighbors[0]],\n",
    "                                                                                            dict_wumpus_probs[neighbors[1]],\n",
    "                                                                                            dict_wumpus_probs[neighbors[2]]])\n",
    "            else: \n",
    "                dict_stench_probs[cell] = ConditionalProbabilityTable([[0, 0, 0, 0, 0, 1.0],\n",
    "                                                                       [0, 0, 0, 0, 1, 0.0],\n",
    "                                                                       [0, 0, 0, 1, 0, 0.0],\n",
    "                                                                       [0, 0, 0, 1, 1, 1.0],\n",
    "                                                                       [0, 0, 1, 0, 0, 0.0],\n",
    "                                                                       [0, 0, 1, 0, 1, 1.0],\n",
    "                                                                       [0, 0, 1, 1, 0, 0.0],\n",
    "                                                                       [0, 0, 1, 1, 1, 1.0],\n",
    "                                                                       [0, 1, 0, 0, 0, 0.0],\n",
    "                                                                       [0, 1, 0, 0, 1, 1.0],\n",
    "                                                                       [0, 1, 0, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 0, 1, 1, 1.0],\n",
    "                                                                       [0, 1, 1, 0, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 0, 1, 1.0],\n",
    "                                                                       [0, 1, 1, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 0, 0, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 1, 0, 0.0],\n",
    "                                                                       [1, 0, 0, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 1, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 0, 0, 0.0],\n",
    "                                                                       [1, 1, 0, 0, 1, 1.0],\n",
    "                                                                       [1, 0, 1, 1, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 1, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 0, 1, 1, 1.0],\n",
    "                                                                       [1, 1, 1, 0, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 1, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 1, 1, 1.0]], [dict_wumpus_probs[neighbors[0]],\n",
    "                                                                                               dict_wumpus_probs[neighbors[1]],\n",
    "                                                                                               dict_wumpus_probs[neighbors[2]],\n",
    "                                                                                               dict_wumpus_probs[neighbors[3]]])\n",
    "        # Create states\n",
    "        wumpus_state = State(wumpus_location_dist)\n",
    "        \n",
    "        wumpus_cpd_states = {}\n",
    "        for cell in all_cells:\n",
    "            wumpus_cpd_states[cell] = State(dict_wumpus_probs[cell])\n",
    "        \n",
    "        stench_cpd_states = {}\n",
    "        for cell in all_cells:\n",
    "            stench_cpd_states[cell] = State(dict_stench_probs[cell])\n",
    "        \n",
    "        # Model\n",
    "        model_wumpus = BayesianNetwork(\"model_wumpus_stenches\")\n",
    "        \n",
    "        # Add states\n",
    "        model_wumpus.add_state(wumpus_state)\n",
    "        for cell in all_cells:\n",
    "            model_wumpus.add_state(wumpus_cpd_states[cell])\n",
    "        for cell in all_cells:\n",
    "            model_wumpus.add_state(stench_cpd_states[cell])\n",
    "        \n",
    "        # Add edges\n",
    "        for cell in all_cells:\n",
    "            model_wumpus.add_edge(wumpus_state, wumpus_cpd_states[cell])\n",
    "        for cell in all_cells:\n",
    "            for n in dict_neighbors[cell]:\n",
    "                model_wumpus.add_edge(wumpus_cpd_states[n], stench_cpd_states[cell])\n",
    "        \n",
    "        model_wumpus.bake()\n",
    "        return model_wumpus\n",
    "    \n",
    "    # Build a probabilistic model for pit and breeze locations\n",
    "    def create_model_pits(self):\n",
    "        # All locations in the grid\n",
    "        all_cells = list_all_locations(self.box_width, self.box_height)\n",
    "        \n",
    "        # Dictionary with discrete distributions for pits (a discrete distribution for each cell)\n",
    "        dict_pit_probs = {}\n",
    "        for cell in all_cells:\n",
    "            if cell.x == 0 and cell.y == 0:\n",
    "                dict_pit_probs[cell] = DiscreteDistribution({True: 0.0, False: 1.0})\n",
    "            else:\n",
    "                dict_pit_probs[cell] = DiscreteDistribution({True: self.pit_prob, False: 1 - self.pit_prob})\n",
    "        \n",
    "        # Dictionary with breeze CPDs (a CPD for each cell - probability of breeze at this cell)\n",
    "        dict_breeze_probs = {}\n",
    "        dict_neighbors = {} # dict where keys and values are cells and their neighbors respectively\n",
    "        for cell in all_cells:\n",
    "            neighbors = cell.adjacent_cells(self.box_width, self.box_height)\n",
    "            dict_neighbors[cell] = neighbors\n",
    "            if len(neighbors) == 2:\n",
    "                dict_breeze_probs[cell] = ConditionalProbabilityTable([[0, 0, 0, 1.0],\n",
    "                                                                       [0, 0, 1, 0.0],\n",
    "                                                                       [0, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 1.0]], [dict_pit_probs[neighbors[0]],\n",
    "                                                                                         dict_pit_probs[neighbors[1]]])\n",
    "            elif len(neighbors) == 3:\n",
    "                dict_breeze_probs[cell] = ConditionalProbabilityTable([[0, 0, 0, 0, 1.0],\n",
    "                                                                       [0, 0, 0, 1, 0.0],\n",
    "                                                                       [0, 0, 1, 0, 0.0],\n",
    "                                                                       [0, 0, 1, 1, 1.0],\n",
    "                                                                       [0, 1, 0, 0, 0.0],\n",
    "                                                                       [0, 1, 0, 1, 1.0],\n",
    "                                                                       [0, 1, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 0, 1, 1.0],\n",
    "                                                                       [1, 0, 1, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 0, 0.0],\n",
    "                                                                       [1, 1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 1, 1.0]], [dict_pit_probs[neighbors[0]],\n",
    "                                                                                            dict_pit_probs[neighbors[1]],\n",
    "                                                                                            dict_pit_probs[neighbors[2]]])\n",
    "            else: \n",
    "                dict_breeze_probs[cell] = ConditionalProbabilityTable([[0, 0, 0, 0, 0, 1.0],\n",
    "                                                                       [0, 0, 0, 0, 1, 0.0],\n",
    "                                                                       [0, 0, 0, 1, 0, 0.0],\n",
    "                                                                       [0, 0, 0, 1, 1, 1.0],\n",
    "                                                                       [0, 0, 1, 0, 0, 0.0],\n",
    "                                                                       [0, 0, 1, 0, 1, 1.0],\n",
    "                                                                       [0, 0, 1, 1, 0, 0.0],\n",
    "                                                                       [0, 0, 1, 1, 1, 1.0],\n",
    "                                                                       [0, 1, 0, 0, 0, 0.0],\n",
    "                                                                       [0, 1, 0, 0, 1, 1.0],\n",
    "                                                                       [0, 1, 0, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 0, 1, 1, 1.0],\n",
    "                                                                       [0, 1, 1, 0, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 0, 1, 1.0],\n",
    "                                                                       [0, 1, 1, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 0, 0, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 1, 0, 0.0],\n",
    "                                                                       [1, 0, 0, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 1, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 0, 0, 0.0],\n",
    "                                                                       [1, 1, 0, 0, 1, 1.0],\n",
    "                                                                       [1, 0, 1, 1, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 1, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 0, 1, 1, 1.0],\n",
    "                                                                       [1, 1, 1, 0, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 1, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 1, 1, 1.0]], [dict_pit_probs[neighbors[0]],\n",
    "                                                                                               dict_pit_probs[neighbors[1]],\n",
    "                                                                                               dict_pit_probs[neighbors[2]],\n",
    "                                                                                               dict_pit_probs[neighbors[3]]])\n",
    "        \n",
    "        # Create states\n",
    "        pit_states = {}\n",
    "        for cell in all_cells:\n",
    "            pit_states[cell] = State(dict_pit_probs[cell])\n",
    "        \n",
    "        breeze_cpd_states = {}\n",
    "        for cell in all_cells:\n",
    "            breeze_cpd_states[cell] = State(dict_breeze_probs[cell])\n",
    "        \n",
    "        # Model\n",
    "        model_pits = BayesianNetwork(\"model_pits_breezes\")\n",
    "        \n",
    "        # Add states\n",
    "        for cell in all_cells:\n",
    "            model_pits.add_state(pit_states[cell])\n",
    "        for cell in all_cells:\n",
    "            model_pits.add_state(breeze_cpd_states[cell])\n",
    "        \n",
    "        # Add edges\n",
    "        for cell in all_cells:\n",
    "            for n in dict_neighbors[cell]:\n",
    "                model_pits.add_edge(pit_states[n], breeze_cpd_states[cell])\n",
    "        \n",
    "        model_pits.bake()\n",
    "        return model_pits\n",
    "        \n",
    "    def select_action(self, percept):\n",
    "        \n",
    "        # List of all locations\n",
    "        all_cells = list_all_locations(self.box_width, self.box_height)\n",
    "        \n",
    "        # Dictionary where keys and values are cells and their neighbors respectively\n",
    "        dict_neighbors = {cell : cell.adjacent_cells(self.box_width, self.box_height) for cell in all_cells}\n",
    "        \n",
    "        # Update agent's variables\n",
    "        visiting_new_location = self.agent_state.location not in self.visited_locations\n",
    "        if visiting_new_location:\n",
    "            self.visited_locations.add(self.agent_state.location)\n",
    "        if percept.breeze:\n",
    "            self.breeze_locations.add(self.agent_state.location)\n",
    "        if percept.stench:\n",
    "            self.stench_locations.add(self.agent_state.location)\n",
    "        new_heard_scream = self.heard_scream or percept.scream\n",
    "        self.heard_scream = new_heard_scream\n",
    "        self.perceives_glitter = percept.glitter\n",
    "        self.perceives_bump = percept.bump\n",
    "        \n",
    "        board_tensor = self.encode_belief_state() # encode belief state\n",
    "        if self.collector is not None: # record the state if collecting experience\n",
    "            self.collector.store_state(state=board_tensor)      \n",
    "        \n",
    "        # Predict wumpus probabilities for each cell if visiting a new location or if just shot an arrow and killed the wumpus\n",
    "        update_wumpus_probs = visiting_new_location or (not visiting_new_location and percept.scream)\n",
    "        if update_wumpus_probs:\n",
    "            if new_heard_scream: # if wumpus is not alive, all probabilities are 0\n",
    "                new_inferred_wumpus_probs = {cell : 0.0 for cell in all_cells}\n",
    "            else: # create a prob model and perform inference\n",
    "                model_wumpus = self.create_model_wumpus()\n",
    "                \n",
    "                # Observations of wumpus and stenches\n",
    "                observations_wumpus = [None]\n",
    "                for cell in all_cells:\n",
    "                    if cell in self.visited_locations:\n",
    "                        observations_wumpus.append(False)\n",
    "                    else:\n",
    "                        observations_wumpus.append(None)\n",
    "                for cell in all_cells:\n",
    "                    if cell in self.stench_locations:\n",
    "                        observations_wumpus.append(True)\n",
    "                    elif cell not in self.visited_locations:\n",
    "                        observations_wumpus.append(None)\n",
    "                    else: # a visited location but no stench was observed\n",
    "                        observations_wumpus.append(False)\n",
    "                \n",
    "                # Compute the probabilities of wumpus\n",
    "                predict_wumpus_probs = model_wumpus.predict_proba([observations_wumpus])\n",
    "                new_inferred_wumpus_probs = predict_wumpus_probs[0][0].parameters[0]\n",
    "            self.inferred_wumpus_probs = new_inferred_wumpus_probs # update agent's inferred_wumpus_probs\n",
    "        else:\n",
    "            new_inferred_wumpus_probs = self.inferred_wumpus_probs\n",
    "        \n",
    "        \n",
    "        # Predict probabilities of there being a pit at each cell\n",
    "        # Create a prob model and perform inference if visiting a new location\n",
    "        \n",
    "        update_pit_probs = visiting_new_location\n",
    "        if update_pit_probs:\n",
    "            model_pits = self.create_model_pits()\n",
    "            \n",
    "            # Observations of pits and breezes\n",
    "            observations_pits = []\n",
    "            for cell in all_cells:\n",
    "                if cell in self.visited_locations:\n",
    "                    observations_pits.append(False)\n",
    "                else:\n",
    "                    observations_pits.append(None)\n",
    "            for cell in all_cells:\n",
    "                if cell in self.breeze_locations:\n",
    "                    observations_pits.append(True)\n",
    "                elif cell not in self.visited_locations:\n",
    "                    observations_pits.append(None)\n",
    "                else: # a visited location but no breeze was observed\n",
    "                    observations_pits.append(False)\n",
    "            \n",
    "            # Compute the new pit probabilities\n",
    "            predict_pit_probs = model_pits.predict_proba([observations_pits])\n",
    "            new_inferred_pit_probs = {}\n",
    "            for i, cell in enumerate(all_cells):\n",
    "                if isinstance(predict_pit_probs[0][i], Distribution):\n",
    "                    new_inferred_pit_probs[cell] = predict_pit_probs[0][i].parameters[0][True]\n",
    "                else: # there was observation of False at this cell\n",
    "                    new_inferred_pit_probs[cell] = 0.0\n",
    "            self.inferred_pit_probs = new_inferred_pit_probs # update agent's inferred_pit_probs\n",
    "        else:\n",
    "            new_inferred_pit_probs = self.inferred_pit_probs\n",
    "        \n",
    "        # Find safe locations where probabilities of wumpus and pits are lower than the tolerance value\n",
    "        def safe_locations_list(tolerance, locations_list, pit_probs, wumpus_probs):\n",
    "            safe_locations = [loc for loc in locations_list if (pit_probs[loc] < tolerance and wumpus_probs[loc] < tolerance)]\n",
    "            return safe_locations\n",
    "        \n",
    "        \n",
    "        # Safe locations for beeline home or to reach a new location\n",
    "        safe_locations_beeline = safe_locations_list(0.01, all_cells, new_inferred_pit_probs, new_inferred_wumpus_probs)\n",
    "        \n",
    "        # Safe locations to explore the grid\n",
    "        safe_locations_search = safe_locations_list(0.4, all_cells, new_inferred_pit_probs, new_inferred_wumpus_probs)\n",
    "                \n",
    "        # Safe locations adjacent to the agent's location (tolerance=0.4)\n",
    "        adjacent_safe_locations = [loc for loc in self.agent_state.location.adjacent_cells(self.box_width, self.box_height) \\\n",
    "                                   if loc in safe_locations_search]\n",
    "        \n",
    "        # Locations where prob of wumpus is greater than 0.49 (agent can try to shoot an arrow there)\n",
    "        likely_wumpus_locations = [loc for loc in all_cells if new_inferred_wumpus_probs[loc] > 0.49]\n",
    "        # Locations where prob of wumpus is greater than 0.49 that can be reached via cells in safe_locations_beeline\n",
    "        reachable_likely_wumpus_locations = [loc for loc in likely_wumpus_locations \\\n",
    "                                             if any(neighbor in safe_locations_beeline for neighbor in dict_neighbors[loc])]\n",
    "        \n",
    "        # Select the next action\n",
    "        if self.agent_state.has_gold: # agent with gold\n",
    "            if self.agent_state.location == Coords(0, 0): # climb with gold\n",
    "                return (self, Action.climb())\n",
    "            else: # beeline home with gold\n",
    "                beeline_home_plan = self.construct_beeline_plan(Coords(0, 0), safe_locations_beeline) \\\n",
    "                                    if self.beeline_action_list == [] else self.beeline_action_list\n",
    "                (new_agent, beeline_action) = self.beeline(beeline_home_plan)\n",
    "                return (new_agent, beeline_action)\n",
    "        else: # agent without gold\n",
    "            if percept.glitter: # grab the gold if glitter\n",
    "                new_agent = copy.deepcopy(self)\n",
    "                new_agent.agent_state.has_gold = True\n",
    "                return (new_agent, Action.grab())\n",
    "            elif self.beeline_action_list != []: # continue beelining to reach a new location / get home without gold / shoot\n",
    "                (new_agent, beeline_action) = self.beeline(self.beeline_action_list)\n",
    "                return (new_agent, beeline_action)\n",
    "            elif reachable_likely_wumpus_locations != [] and self.agent_state.has_arrow: # shoot an arrow at a likely wumpus loc\n",
    "                target_location = random.choice(reachable_likely_wumpus_locations)\n",
    "                locations_beeline_shoot = safe_locations_beeline.copy()\n",
    "                locations_beeline_shoot.append(target_location) # add the target location to locations for beelining\n",
    "                beeline_shoot_plan = self.construct_beeline_plan(target_location, locations_beeline_shoot)\n",
    "                del beeline_shoot_plan[-1] # remove the last action which is a move forward to a likely wumpus location\n",
    "                beeline_shoot_plan.append(Action.shoot()) # add the shoot action to the end of the list\n",
    "                (new_agent, beeline_action) = self.beeline(beeline_shoot_plan)\n",
    "                return (new_agent, beeline_action)\n",
    "            elif self.agent_state.location == Coords(0, 0) and adjacent_safe_locations == []: # unsafe to explore\n",
    "                if not percept.breeze and self.agent_state.has_arrow: # try to kill wumpus if low probability of pits around\n",
    "                    new_agent = copy.deepcopy(self)\n",
    "                    new_agent.agent_state = new_agent.agent_state.use_arrow()\n",
    "                    return (new_agent, Action.shoot())\n",
    "                else: # climb without gold\n",
    "                    return (self, Action.climb())\n",
    "            else: # search for gold\n",
    "                # Not visited locations adjacent to all previously visited locations\n",
    "                potential_visit_locations_set = {adj_loc for loc in self.visited_locations \\\n",
    "                                                for adj_loc in loc.adjacent_cells(self.box_width, self.box_height) \\\n",
    "                                                if adj_loc not in self.visited_locations}\n",
    "                potential_visit_locations_list = list(potential_visit_locations_set)\n",
    "                safe_potential_visit_locations = [loc for loc in potential_visit_locations_list if loc in safe_locations_search]\n",
    "                if safe_potential_visit_locations != []: # new safe locations exist; choose one and create a beeline plan to it\n",
    "                    search_coords_list = []\n",
    "                    search_wumpus_probs = []\n",
    "                    for loc in safe_potential_visit_locations:\n",
    "                        search_coords_list.append(loc)\n",
    "                        search_wumpus_probs.append(new_inferred_wumpus_probs[loc])\n",
    "                    next_location_index = search_wumpus_probs.index(min(search_wumpus_probs)) # find cell with min wumpus prob\n",
    "                    next_location = search_coords_list[next_location_index]\n",
    "                    locations_beeline_search = safe_locations_beeline.copy()\n",
    "                    locations_beeline_search.append(next_location) # add the chosen location to locations for beelining\n",
    "                    beeline_search_plan = self.construct_beeline_plan(next_location, locations_beeline_search)\n",
    "                    (new_agent, beeline_action) = self.beeline(beeline_search_plan)\n",
    "                    return (new_agent, beeline_action)\n",
    "                else: # no new safe locations to explore, beeline home without gold\n",
    "                    beeline_home_plan = self.construct_beeline_plan(Coords(0, 0), safe_locations_beeline)\n",
    "                    beeline_home_plan.append(Action.climb())\n",
    "                    (new_agent, beeline_action) = self.beeline(beeline_home_plan)\n",
    "                    return (new_agent, beeline_action)\n",
    "    \n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def new_agent(cls, box_width, box_height, pit_prob):\n",
    "        return ProbAgent(box_width, box_height, pit_prob, AgentState(), [], set(), set(), set(), False, {}, {}, False, False)\n",
    "      \n",
    "    # Encode belief state using 13 feature planes (each plane is a grid_height x grid_width matrix)\n",
    "    # The state shape is (13, grid_height, grid_width)\n",
    "    \n",
    "    def encode_belief_state(self):\n",
    "        board_tensor = np.zeros((13, self.box_height, self.box_width))\n",
    "        all_cells = list_all_locations(self.box_width, self.box_height)\n",
    "        \n",
    "        # The first plane has a 1 for agent's location and 0s for other locations\n",
    "        board_tensor[0][self.agent_state.location.y][self.agent_state.location.x] = 1\n",
    "        \n",
    "        for cell in all_cells:\n",
    "            if cell in self.visited_locations:\n",
    "                board_tensor[1][cell.y][cell.x] = 1 # 1s for visited locations\n",
    "            if cell in self.stench_locations:\n",
    "                board_tensor[2][cell.y][cell.x] = 1 # 1s for stench locations\n",
    "            if cell in self.breeze_locations:\n",
    "                board_tensor[3][cell.y][cell.x] = 1 # 1s for breeze locations\n",
    "        \n",
    "        if self.agent_state.orientation == Orientation.north: # a plane filled with 1s if Orientation.north\n",
    "            board_tensor[4] = 1\n",
    "        elif self.agent_state.orientation == Orientation.south: # a plane filled with 1s if Orientation.south\n",
    "            board_tensor[5] = 1\n",
    "        elif self.agent_state.orientation == Orientation.east: # a plane filled with 1s if Orientation.east\n",
    "            board_tensor[6] = 1\n",
    "        else: # a plane filled with 1s if Orientation.west\n",
    "            board_tensor[7] = 1\n",
    "        \n",
    "        if self.agent_state.has_gold: # a plane filled with 1s if agent has gold, and 0s otherwise\n",
    "            board_tensor[8] = 1\n",
    "        if self.perceives_glitter: # a plane filled with 1s if agent perceives glitter, and 0s otherwise\n",
    "            board_tensor[9] = 1\n",
    "        if self.agent_state.has_arrow: # a plane filled with 1s if agent has arrow, and 0s otherwise\n",
    "            board_tensor[10] = 1\n",
    "        if self.heard_scream: # a plane filled with 1s if wumpus is not alive, and 0s otherwise\n",
    "            board_tensor[11] = 1\n",
    "        if self.perceives_bump: # a plane filled with 1s if agent perceives bump, and 0s otherwise\n",
    "            board_tensor[12] = 1\n",
    "        \n",
    "        return board_tensor       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b7ced41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games:  1000\n",
      "Total number of moves:  16530\n",
      "Score: 746740\n",
      "avg_reward_per_game: 746.74\n",
      "win_percent: 0.38\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    n_games = 1000\n",
    "    total_moves = 0\n",
    "    score = 0\n",
    "    wins = 0\n",
    "    \n",
    "    collector = ExperienceCollector()\n",
    "    \n",
    "    for i in range(n_games):\n",
    "        agent = ProbAgent.new_agent(4, 4, 0.2)\n",
    "        (env, percept) = Environment.new_game(4, 4, 0.2, True)\n",
    "        total_reward = 0\n",
    "        num_moves = 0\n",
    "        \n",
    "        while not percept.game_over:\n",
    "            agent.set_collector(collector)\n",
    "            (agent, next_action) = agent.select_action(percept)\n",
    "            next_action_int = encode_action_to_int(next_action) # encode action to int\n",
    "            collector.store_action(next_action_int) # add encoded action to collector\n",
    "            (env, percept) = env.apply_action(next_action)\n",
    "            collector.store_reward(percept.reward) # add reward to collector\n",
    "            total_reward += percept.reward\n",
    "            num_moves += 1\n",
    "               \n",
    "        if agent.agent_state.has_gold:\n",
    "            wins += 1\n",
    "        score += total_reward\n",
    "        total_moves += num_moves\n",
    "    \n",
    "    print(\"Number of games: \", n_games)\n",
    "    print(\"Total number of moves: \", total_moves)\n",
    "    print(\"Score:\", score)\n",
    "    print(\"avg_reward_per_game: %.2f\" % (score / n_games))\n",
    "    print(\"win_percent: %.2f\" % (wins / n_games))\n",
    "    \n",
    "    experience = collector.to_buffer() # convert the collector to a buffer\n",
    "    with h5py.File('prob_agent_experience_02', 'w') as exp_out: # save the buffer as a file\n",
    "        experience.serialize(exp_out)\n",
    "       \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b977c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cea4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b6ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
